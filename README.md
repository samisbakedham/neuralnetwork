# neuralnetwork

#samuelsafahi

sigmoid function to normalize inputs
sigmoid derivatives to adjust synaptic weights
input dataset
output dataset
seed random numbers to make calculation
initialize weights randomly with mean 0 to create weight matrix, synaptic weights
Iterate 10,000 times
Define input layer
Normalize the product of the input layer with the synaptic weights
how much did we miss?
multiply how much we missed by the
slope of the sigmoid at the values in outputs
update weights

very simple neural network     
